{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize RNN/NLP Flow\n",
    "## With a toy example\n",
    "### In Tensorflow :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For X\n",
    "batch_size = 2\n",
    "num_seq = 3\n",
    "num_features = 1\n",
    "\n",
    "#For Y\n",
    "num_classes = 1\n",
    "\n",
    "#For RNN Cell\n",
    "state_size = 4 #Num hidden units\n",
    "\n",
    "#For output\n",
    "vocab_size = 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['The'],\n",
       "        ['lazy'],\n",
       "        ['fox']],\n",
       "\n",
       "       [['jumps'],\n",
       "        ['over'],\n",
       "        ['the']]], \n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(['The','lazy','fox','jumps','over','the']).reshape(batch_size,num_seq,num_features) #For visualizing\n",
    "data_int = np.array([0,1,2,3,4,5]).reshape(batch_size,num_seq,num_features) #When things doesn't work without numbers\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['lazy'],\n",
       "        ['fox'],\n",
       "        ['jumps']],\n",
       "\n",
       "       [['over'],\n",
       "        ['the'],\n",
       "        ['brown']]], \n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data = np.array(['lazy','fox','jumps','over','the','brown']).reshape(batch_size,num_seq,num_features)\n",
    "target_data_int = np.array([1,2,3,4,5,0]).reshape(batch_size,num_seq,num_features)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders\n",
    "\n",
    "<img src=\"http://i66.tinypic.com/33m9c37.jpg\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchX_placeholder = tf.placeholder(dtype=tf.string,shape=[batch_size,num_seq,num_features],name='x')\n",
    "batchY_placeholder = tf.placeholder(dtype=tf.string,shape=[batch_size,num_seq,num_classes],name='y')\n",
    "\n",
    "#When things doesn't work without numbers\n",
    "batchX_placeholder_float = tf.placeholder(dtype=tf.float32,shape=[batch_size,num_seq,num_features],name='x_float')\n",
    "batchY_placeholder_float = tf.placeholder(dtype=tf.int32,shape=[batch_size,num_seq,num_classes],name='y_float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[['The']\n",
      "  ['lazy']\n",
      "  ['fox']]\n",
      "\n",
      " [['jumps']\n",
      "  ['over']\n",
      "  ['the']]]\n",
      "\n",
      "Y:\n",
      " [[['lazy']\n",
      "  ['fox']\n",
      "  ['jumps']]\n",
      "\n",
      " [['over']\n",
      "  ['the']\n",
      "  ['brown']]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    feed = {batchX_placeholder : data, batchY_placeholder : target_data}\n",
    "    \n",
    "    x = batchX_placeholder.eval(feed_dict=feed)\n",
    "    y = batchY_placeholder.eval(feed_dict=feed)\n",
    "\n",
    "print('X:\\n',x)\n",
    "print('\\nY:\\n',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose the Y \n",
    "\n",
    "To get the labels series by sequence\n",
    "\n",
    "<img src=\"http://i66.tinypic.com/2qszajs.jpg\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_series = tf.transpose(a=batchY_placeholder, perm=[1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    feed = {batchX_placeholder : data, batchY_placeholder : target_data}\n",
    "    \n",
    "    results = sess.run(fetches=[labels_series],feed_dict=feed)\n",
    "    \n",
    "    _labels_series = np.array(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 1)\n",
      "The labels of the first sequence for all instances in the batch:\n",
      " [[b'lazy']\n",
      " [b'over']]\n",
      "\n",
      "The labels of the second sequence for all instances in the batch:\n",
      " [[b'fox']\n",
      " [b'the']]\n",
      "\n",
      "The labels of the third sequence for all instances in the batch:\n",
      " [[b'jumps']\n",
      " [b'brown']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(_labels_series.shape)\n",
    "print('The labels of the first sequence for all instances in the batch:\\n %s\\n' %_labels_series[0])\n",
    "\n",
    "print('The labels of the second sequence for all instances in the batch:\\n %s\\n' %_labels_series[1])\n",
    "\n",
    "print('The labels of the third sequence for all instances in the batch:\\n %s\\n' %_labels_series[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Cell\n",
    "\n",
    "We will get:\n",
    " - **states_series:** The output (and state because simple RNN) of the cell in each time step\n",
    " - **current_state:** The last state (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=state_size)\n",
    "\n",
    "states_series, current_state = tf.nn.dynamic_rnn(cell=cell,inputs=batchX_placeholder_float,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    \n",
    "    feed = {batchX_placeholder_float : data_int, batchY_placeholder_float : target_data_int}\n",
    "    \n",
    "    results = sess.run(fetches=[states_series,current_state],feed_dict=feed)\n",
    "    \n",
    "    _states_series = np.array(results[0])\n",
    "    _current_state = np.array(results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### States series\n",
    "\n",
    "<img src=\"http://i64.tinypic.com/24z9e83.jpg\" style=\"width:700px\">\n",
    "\n",
    "Note: This is a Simple RNN -> The hidden state and output are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.3828496 ,  0.17064542,  0.67230123,  0.52947646],\n",
       "        [-0.92135811,  0.4982436 ,  0.94858086,  0.94305122]],\n",
       "\n",
       "       [[-0.83673453,  0.47537675,  0.98506325,  0.94341761],\n",
       "        [-0.99640185,  0.81296581,  0.99910688,  0.99777246],\n",
       "        [-0.99906594,  0.88451481,  0.99987727,  0.99950737]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(_states_series.shape)\n",
    "_states_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current/Last state\n",
    "\n",
    "<img src=\"http://i66.tinypic.com/sffjo1.jpg\" style=\"width:700px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.92135811,  0.4982436 ,  0.94858086,  0.94305122],\n",
       "       [-0.99906594,  0.88451481,  0.99987727,  0.99950737]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(_current_state.shape)\n",
    "_current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transpose state series\n",
    "\n",
    "To get the states by sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states_series = tf.transpose(states_series,[1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    tf.global_variables_initializer().run()\n",
    "    feed = {batchX_placeholder_float : data_int, batchY_placeholder_float : target_data_int}\n",
    "    \n",
    "    results = sess.run(fetches=[states_series],feed_dict=feed)\n",
    "    \n",
    "    _states_series = np.array(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sequence_length,batch_size,state_size) <-> (3, 2, 4) \n",
      "\n",
      "The state/output of the first sequence for all instances in the batch:\n",
      " [[ 0.          0.          0.          0.        ]\n",
      " [ 0.98410064  0.98064345 -0.95231408 -0.96098006]]\n",
      "\n",
      "The state/output of the second sequence for all instances in the batch:\n",
      " [[ 0.66651201  0.64771891 -0.55021465 -0.57358873]\n",
      " [ 0.98326427  0.9985764  -0.98046207 -0.99799967]]\n",
      "\n",
      "The state/output of the third sequence for all instances in the batch:\n",
      " [[ 0.79220331  0.95351785 -0.83097667 -0.95784646]\n",
      " [ 0.99657929  0.99970174 -0.99398762 -0.99945265]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('(sequence_length,batch_size,state_size) <->',_states_series.shape,'\\n')\n",
    "print('The state/output of the first sequence for all instances in the batch:\\n %s\\n' %_states_series[0])\n",
    "\n",
    "print('The state/output of the second sequence for all instances in the batch:\\n %s\\n' %_states_series[1])\n",
    "\n",
    "print('The state/output of the third sequence for all instances in the batch:\\n %s\\n' %_states_series[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute predictions - Last layer\n",
    "\n",
    "With the outputs of the RNN cell let's make the computations for the prediction on the last layer. But before doing that we need to:\n",
    "\n",
    "### Flatten labels series & states series\n",
    "\n",
    "\n",
    "This is for compute the matmul\n",
    "\n",
    "In summary, now **doesn't matter from which** observation/step **the prediction is**, so we **squash** into 1 minus dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flatten labels series**\n",
    "\n",
    "<img src=\"http://i64.tinypic.com/214pjye.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_targets = tf.reshape(tensor=batchY_placeholder,shape=[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    tf.global_variables_initializer().run()\n",
    "    feed = {batchY_placeholder : target_data}\n",
    "    \n",
    "    results = sess.run(fetches=[flat_targets],feed_dict=feed)\n",
    "    \n",
    "    _flat_targets = np.array(results[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From shape: (2, 3, 1)  to shape:  (6,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([b'lazy', b'fox', b'jumps', b'over', b'the', b'brown'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('From shape:',batchY_placeholder.get_shape(),' to shape: ',_flat_targets.shape)\n",
    "_flat_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flatten outputs**\n",
    "\n",
    "<img src=\"http://i63.tinypic.com/24b4w2a.jpg\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_outputs = tf.reshape(tensor=states_series,shape=[-1,state_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    tf.global_variables_initializer().run()\n",
    "    feed = {batchX_placeholder_float: data_int}\n",
    "    \n",
    "    results = sess.run(fetches=[flat_outputs],feed_dict=feed)\n",
    "    \n",
    "    _flat_outputs = np.array(results[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From shape: (3, 2, 4)  to shape:  (6, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.78044307, -0.49088821, -0.97092193, -0.36441708],\n",
       "       [ 0.3353413 , -0.17718661, -0.60608613, -0.12663972],\n",
       "       [ 0.80831087, -0.86220902, -0.99502432, -0.55181724],\n",
       "       [ 0.44298396, -0.5932681 , -0.90480542, -0.32963246],\n",
       "       [ 0.91816044, -0.94902056, -0.99890029, -0.77325529]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('From shape:',states_series.get_shape(),' to shape: ',_flat_outputs.shape)\n",
    "_flat_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute prediction\n",
    "\n",
    "Matmul with flattened inputs => **Logits**\n",
    "\n",
    "<img src=\"http://i68.tinypic.com/6zaogi.jpg\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform(shape=[state_size,vocab_size]),dtype=tf.float32,name='W_out')\n",
    "b = tf.Variable(tf.constant(0.1,shape=[vocab_size]),dtype=tf.float32,name='b_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = tf.matmul(flat_outputs,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    tf.global_variables_initializer().run()\n",
    "    feed = {batchX_placeholder_float: data_int, batchY_placeholder_float : target_data_int}\n",
    "    \n",
    "    results = sess.run(fetches=[logits],feed_dict=feed)\n",
    "    \n",
    "    _logits = np.array(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
       "         0.1       ],\n",
       "       [ 1.49434376,  1.78906667,  0.89901924,  1.78935158,  1.72661102,\n",
       "         1.89934814],\n",
       "       [ 0.73228633,  0.92536426,  0.48823631,  0.97955954,  0.91697717,\n",
       "         1.00008118],\n",
       "       [ 1.4169637 ,  1.56162679,  0.66684574,  1.58952439,  1.62763298,\n",
       "         1.72019303],\n",
       "       [ 1.19641578,  1.24528551,  0.53684908,  1.20129764,  1.2815069 ,\n",
       "         1.30902803],\n",
       "       [ 1.64198267,  1.87490857,  0.88617158,  1.85626113,  1.84925163,\n",
       "         2.0070045 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(_logits.shape)\n",
    "_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which means...\n",
    "\n",
    "Note: Random logits implies random probabilities ;) so don't expect a sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>lazy</th>\n",
       "      <th>fox</th>\n",
       "      <th>jumps</th>\n",
       "      <th>over</th>\n",
       "      <th>brown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lazy</th>\n",
       "      <td>1.494344</td>\n",
       "      <td>1.789067</td>\n",
       "      <td>0.899019</td>\n",
       "      <td>1.789352</td>\n",
       "      <td>1.726611</td>\n",
       "      <td>1.899348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>0.732286</td>\n",
       "      <td>0.925364</td>\n",
       "      <td>0.488236</td>\n",
       "      <td>0.979560</td>\n",
       "      <td>0.916977</td>\n",
       "      <td>1.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jumps</th>\n",
       "      <td>1.416964</td>\n",
       "      <td>1.561627</td>\n",
       "      <td>0.666846</td>\n",
       "      <td>1.589524</td>\n",
       "      <td>1.627633</td>\n",
       "      <td>1.720193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over</th>\n",
       "      <td>1.196416</td>\n",
       "      <td>1.245286</td>\n",
       "      <td>0.536849</td>\n",
       "      <td>1.201298</td>\n",
       "      <td>1.281507</td>\n",
       "      <td>1.309028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brown</th>\n",
       "      <td>1.641983</td>\n",
       "      <td>1.874909</td>\n",
       "      <td>0.886172</td>\n",
       "      <td>1.856261</td>\n",
       "      <td>1.849252</td>\n",
       "      <td>2.007004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            The      lazy       fox     jumps      over     brown\n",
       "The    0.100000  0.100000  0.100000  0.100000  0.100000  0.100000\n",
       "lazy   1.494344  1.789067  0.899019  1.789352  1.726611  1.899348\n",
       "fox    0.732286  0.925364  0.488236  0.979560  0.916977  1.000081\n",
       "jumps  1.416964  1.561627  0.666846  1.589524  1.627633  1.720193\n",
       "over   1.196416  1.245286  0.536849  1.201298  1.281507  1.309028\n",
       "brown  1.641983  1.874909  0.886172  1.856261  1.849252  2.007004"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(_logits)\n",
    "df.columns = ['The','lazy','fox','jumps','over','brown']\n",
    "df.index = ['The','lazy','fox','jumps','over','brown']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss with Sparse Softmax cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It's necessary numbers\n",
    "flat_targets = tf.reshape(tensor=batchY_placeholder_float,shape=[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=flat_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    tf.global_variables_initializer().run()\n",
    "    feed = {batchX_placeholder_float: data_int, batchY_placeholder_float : target_data_int}\n",
    "    \n",
    "    results = sess.run(fetches=[loss],feed_dict=feed)\n",
    "    \n",
    "    _loss = np.array(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.79175949,  2.55482769,  1.99774253,  1.72456992,  1.12336171,\n",
       "        1.55354738], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
