{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize RNN/NLP Flow\n",
    "## With a toy example\n",
    "### In Tensorflow :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For X\n",
    "batch_size = 2\n",
    "num_seq = 3\n",
    "num_features = 1\n",
    "\n",
    "#For Y\n",
    "num_classes = 1\n",
    "\n",
    "#For RNN Cell\n",
    "state_size = 4 #Num hidden units\n",
    "\n",
    "#For output\n",
    "vocab_size = 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['The'],\n",
       "        ['lazy'],\n",
       "        ['fox']],\n",
       "\n",
       "       [['jumps'],\n",
       "        ['over'],\n",
       "        ['the']]], \n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(['The','lazy','fox','jumps','over','the']).reshape(batch_size,num_seq,num_features) #For visualizing\n",
    "data_int = np.array([0,1,2,3,4,5]).reshape(batch_size,num_seq,num_features) #When things doesn't work without numbers\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['lazy'],\n",
       "        ['fox'],\n",
       "        ['jumps']],\n",
       "\n",
       "       [['over'],\n",
       "        ['the'],\n",
       "        ['brown']]], \n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data = np.array(['lazy','fox','jumps','over','the','brown']).reshape(batch_size,num_seq,num_features)\n",
    "target_data_int = np.array([1,2,3,4,5,0]).reshape(batch_size,num_seq,num_features)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders\n",
    "\n",
    "<img src=\"http://i66.tinypic.com/33m9c37.jpg\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchX_placeholder = tf.placeholder(dtype=tf.string,shape=[batch_size,num_seq,num_features],name='x')\n",
    "batchY_placeholder = tf.placeholder(dtype=tf.string,shape=[batch_size,num_seq,num_classes],name='y')\n",
    "\n",
    "#When things doesn't work without numbers\n",
    "batchX_placeholder_float = tf.placeholder(dtype=tf.float32,shape=[batch_size,num_seq,num_features],name='x_float')\n",
    "batchY_placeholder_float = tf.placeholder(dtype=tf.int32,shape=[batch_size,num_seq,num_classes],name='y_float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[['The']\n",
      "  ['lazy']\n",
      "  ['fox']]\n",
      "\n",
      " [['jumps']\n",
      "  ['over']\n",
      "  ['the']]]\n",
      "\n",
      "Y:\n",
      " [[['lazy']\n",
      "  ['fox']\n",
      "  ['jumps']]\n",
      "\n",
      " [['over']\n",
      "  ['the']\n",
      "  ['brown']]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    feed = {batchX_placeholder : data, batchY_placeholder : target_data}\n",
    "    \n",
    "    x = batchX_placeholder.eval(feed_dict=feed)\n",
    "    y = batchY_placeholder.eval(feed_dict=feed)\n",
    "\n",
    "print('X:\\n',x)\n",
    "print('\\nY:\\n',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose the Y \n",
    "\n",
    "To get the labels series by sequence\n",
    "\n",
    "<img src=\"http://i66.tinypic.com/2qszajs.jpg\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_series = tf.transpose(a=batchY_placeholder, perm=[1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    feed = {batchX_placeholder : data, batchY_placeholder : target_data}\n",
    "    \n",
    "    results = sess.run(fetches=[labels_series],feed_dict=feed)\n",
    "    \n",
    "    _labels_series = np.array(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 1)\n",
      "The labels of the first sequence for all instances in the batch:\n",
      " [[b'lazy']\n",
      " [b'over']]\n",
      "\n",
      "The labels of the second sequence for all instances in the batch:\n",
      " [[b'fox']\n",
      " [b'the']]\n",
      "\n",
      "The labels of the third sequence for all instances in the batch:\n",
      " [[b'jumps']\n",
      " [b'brown']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(_labels_series.shape)\n",
    "print('The labels of the first sequence for all instances in the batch:\\n %s\\n' %_labels_series[0])\n",
    "\n",
    "print('The labels of the second sequence for all instances in the batch:\\n %s\\n' %_labels_series[1])\n",
    "\n",
    "print('The labels of the third sequence for all instances in the batch:\\n %s\\n' %_labels_series[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Cell\n",
    "\n",
    "We will get:\n",
    " - **states_series:** The output (and state because simple RNN) of the cell in each time step\n",
    " - **current_state:** The last state (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=state_size)\n",
    "\n",
    "states_series, current_state = tf.nn.dynamic_rnn(cell=cell,inputs=batchX_placeholder_float,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    \n",
    "    feed = {batchX_placeholder_float : data_int, batchY_placeholder_float : target_data_int}\n",
    "    \n",
    "    results = sess.run(fetches=[states_series,current_state],feed_dict=feed)\n",
    "    \n",
    "    _states_series = np.array(results[0])\n",
    "    _current_state = np.array(results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### States series\n",
    "\n",
    "<img src=\"http://i64.tinypic.com/24z9e83.jpg\" style=\"width:700px\">\n",
    "\n",
    "Note: This is a Simple RNN -> The hidden state and output are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.43238673, -0.4710772 ,  0.33191839,  0.37335438],\n",
       "        [ 0.53553414, -0.96528101,  0.5895828 ,  0.76694363]],\n",
       "\n",
       "       [[ 0.8828373 , -0.91116798,  0.77588522,  0.82648605],\n",
       "        [ 0.82506567, -0.99947053,  0.88808799,  0.96316737],\n",
       "        [ 0.91611695, -0.99985313,  0.93506902,  0.98136932]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(_states_series.shape)\n",
    "_states_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current/Last state\n",
    "\n",
    "<img src=\"http://i66.tinypic.com/sffjo1.jpg\" style=\"width:700px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.53553414, -0.96528101,  0.5895828 ,  0.76694363],\n",
       "       [ 0.91611695, -0.99985313,  0.93506902,  0.98136932]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(_current_state.shape)\n",
    "_current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transpose state series\n",
    "\n",
    "To get the states by sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states_series = tf.transpose(states_series,[1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    tf.global_variables_initializer().run()\n",
    "    feed = {batchX_placeholder_float : data_int, batchY_placeholder_float : target_data_int}\n",
    "    \n",
    "    results = sess.run(fetches=[states_series],feed_dict=feed)\n",
    "    \n",
    "    _states_series = np.array(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sequence_length,batch_size,state_size) <-> (3, 2, 4) \n",
      "\n",
      "The state/output of the first sequence for all instances in the batch:\n",
      " [[ 0.          0.          0.          0.        ]\n",
      " [ 0.37008941 -0.93614703  0.37905324 -0.59634608]]\n",
      "\n",
      "The state/output of the second sequence for all instances in the batch:\n",
      " [[ 0.12878965 -0.51436377  0.13220608 -0.22522394]\n",
      " [ 0.89266753 -0.9314726  -0.38482139 -0.13724595]]\n",
      "\n",
      "The state/output of the third sequence for all instances in the batch:\n",
      " [[ 0.59113258 -0.71202987 -0.20717673 -0.02601799]\n",
      " [ 0.69573092 -0.98382539  0.16059849 -0.71726888]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('(sequence_length,batch_size,state_size) <->',_states_series.shape,'\\n')\n",
    "print('The state/output of the first sequence for all instances in the batch:\\n %s\\n' %_states_series[0])\n",
    "\n",
    "print('The state/output of the second sequence for all instances in the batch:\\n %s\\n' %_states_series[1])\n",
    "\n",
    "print('The state/output of the third sequence for all instances in the batch:\\n %s\\n' %_states_series[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute predictions - Last layer\n",
    "\n",
    "With the outputs of the RNN cell let's make the computations for the prediction on the last layer. But before doing that we need to:\n",
    "\n",
    "### Flatten labels series & states series\n",
    "\n",
    "\n",
    "This is for compute the matmul\n",
    "\n",
    "In summary, now **doesn't matter from which** observation/step **the prediction is**, so we **squash** into 1 minus dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flatten labels series**\n",
    "\n",
    "<img src=\"http://i64.tinypic.com/214pjye.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_targets = tf.reshape(tensor=batchY_placeholder,shape=[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    tf.global_variables_initializer().run()\n",
    "    feed = {batchY_placeholder : target_data}\n",
    "    \n",
    "    results = sess.run(fetches=[flat_targets],feed_dict=feed)\n",
    "    \n",
    "    _flat_targets = np.array(results[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From shape: (2, 3, 1)  to shape:  (6,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([b'lazy', b'fox', b'jumps', b'over', b'the', b'brown'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('From shape:',batchY_placeholder.get_shape(),' to shape: ',_flat_targets.shape)\n",
    "_flat_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flatten outputs**\n",
    "\n",
    "<img src=\"http://i63.tinypic.com/24b4w2a.jpg\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_outputs = tf.reshape(tensor=states_series,shape=[-1,state_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    tf.global_variables_initializer().run()\n",
    "    feed = {batchX_placeholder_float: data_int}\n",
    "    \n",
    "    results = sess.run(fetches=[flat_outputs],feed_dict=feed)\n",
    "    \n",
    "    _flat_outputs = np.array(results[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From shape: (3, 2, 4)  to shape:  (6, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.69274813, -0.98025954, -0.9797079 , -0.41708142],\n",
       "       [-0.2769787 , -0.64579523, -0.64308214, -0.14697887],\n",
       "       [-0.93733555, -0.99982619, -0.99946183, -0.32860491],\n",
       "       [-0.67917567, -0.987589  , -0.96989709,  0.00420785],\n",
       "       [-0.96817905, -0.99997431, -0.99989015, -0.51451689]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('From shape:',states_series.get_shape(),' to shape: ',_flat_outputs.shape)\n",
    "_flat_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute prediction\n",
    "\n",
    "Matmul with flattened inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform(shape=[state_size,vocab_size]),dtype=tf.float32,name='W_out')\n",
    "b = tf.Variable(tf.constant(0.1,shape=[vocab_size]),dtype=tf.float32,name='b_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = tf.matmul(flat_outputs,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    tf.global_variables_initializer().run()\n",
    "    feed = {batchX_placeholder_float: data_int, batchY_placeholder_float : target_data_int}\n",
    "    \n",
    "    results = sess.run(fetches=[logits],feed_dict=feed)\n",
    "    \n",
    "    _logits = np.array(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.1       ,  0.1       ,  0.1       ,  0.1       ,  0.1       ,\n",
       "         0.1       ],\n",
       "       [-0.21786088, -1.3025943 , -1.25121176, -0.55337501, -0.96768951,\n",
       "        -0.08923074],\n",
       "       [-0.04639579, -0.63087821, -0.60588175, -0.2414602 , -0.50227517,\n",
       "        -0.05099357],\n",
       "       [-0.13417581, -1.40281415, -1.19780445, -0.63100964, -1.2592032 ,\n",
       "        -0.45974395],\n",
       "       [ 0.00769539, -0.89560258, -0.7360934 , -0.3729488 , -0.93226361,\n",
       "        -0.32307422],\n",
       "       [-0.15511206, -1.49623537, -1.27623796, -0.67309195, -1.32619226,\n",
       "        -0.45543543]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(_logits.shape)\n",
    "_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities with Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#It's necessary numbers\n",
    "flat_targets = tf.reshape(tensor=batchY_placeholder_float,shape=[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=flat_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    tf.global_variables_initializer().run()\n",
    "    feed = {batchX_placeholder_float: data_int, batchY_placeholder_float : target_data_int}\n",
    "    \n",
    "    results = sess.run(fetches=[probs],feed_dict=feed)\n",
    "    \n",
    "    _probs = np.array(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.79175949,  2.04980779,  1.61992574,  1.51073301,  2.08370972,\n",
       "        1.98567867], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
