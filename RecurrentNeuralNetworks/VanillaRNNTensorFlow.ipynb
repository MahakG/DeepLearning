{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla RNN\n",
    "\n",
    "**Â¿Could we 'teach' a RNN to sum?**\n",
    "\n",
    "## Task\n",
    "\n",
    "Given an array of length 10, we need to determine the sum of the array\n",
    "\n",
    "**Example:**<br>\n",
    "*input* : [0,1,2,3,4,5,6,7,8,9] <br>\n",
    "*output* : 45<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course doing this is a silly task, but **let's train a RNN and let's see if see figures out what she has to do**\n",
    "\n",
    "Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "### Train Data\n",
    "\n",
    "The train input will just be arrays of length 10 with random integers in the interval [0,10)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numInstances = 5000\n",
    "seq_length = 10\n",
    "output_size = 1\n",
    " \n",
    "train_input = np.array(np.random.choice(10,numInstances*seq_length)).reshape(-1,seq_length,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5000, 10, 1)\n",
      "First as sample: [4 5 1 5 1 8 1 2 9 6]\n"
     ]
    }
   ],
   "source": [
    "len(train_input)\n",
    "print('Train shape:', train_input.shape)\n",
    "print('First as sample: %s' % train_input[0].reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train output will be the sum of the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5000, 1)\n",
      "First as sample: [42]\n"
     ]
    }
   ],
   "source": [
    "train_output = []\n",
    " \n",
    "for i in train_input:\n",
    "    train_output.append(np.sum(i))\n",
    "    \n",
    "train_output = np.array(train_output)\n",
    "train_output = train_output.reshape(-1,1)\n",
    "\n",
    "print('Train shape:', train_output.shape)\n",
    "print('First as sample: %s' % train_output[0].reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data\n",
    "\n",
    "The same but for testing at the end, you know..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "(5000, 10, 1)\n",
      "(5000, 1)\n"
     ]
    }
   ],
   "source": [
    "test_input = np.array(np.random.choice(10,numInstances*seq_length)).reshape(-1,10,1)\n",
    "test_output = []\n",
    " \n",
    "for i in test_input:\n",
    "    test_output.append(np.sum(i))\n",
    "    \n",
    "test_output = np.array(test_output)\n",
    "test_output = test_output.reshape(-1,1)\n",
    "\n",
    "print('Shapes:')\n",
    "print(test_input.shape)\n",
    "print(test_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders\n",
    "\n",
    "The Placeholders for a RNN are a little bit different, the structure is:<br>\n",
    "\n",
    "**Data** : [Batch Size, Sequence Length, Number of Sequences]\n",
    "\n",
    "---\n",
    "\n",
    "In our example:<br>\n",
    "**Data** : [AnyBatchSize, 10, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"data:0\", shape=(?, 10, 1), dtype=float32)\n",
      "Tensor(\"target:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "n_sequences = 1\n",
    "\n",
    "data = tf.placeholder(dtype=tf.float32,shape=[None,seq_length,n_sequences],name='data')\n",
    "target = tf.placeholder(dtype=tf.float32,shape=[None,output_size],name='target')\n",
    "\n",
    "print(data)\n",
    "print(target)"
   ]
  },
  {
   "attachments": {
    "1HiddenRNNFeed.PNG": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABkAAAEYCAYAAACpwl1yAAAACXBIWXMAAC4jAAAuIwF4pT92AAAAIGNIUk0AAHolAACAgwAA+f8AAIDpAAB1MAAA6mAAADqYAAAXb5JfxUYAAAHXSURBVHja7NyxShxRFIDhf3RMGiGSwmC5RYJYBGx8BbUJCKlDKiVtirxA9Al8AZtAAr6CimBlE7CyClZ2i0WahKycFLmDs7LDOrMzkoX/wmWHO8P95pxz5+6yC5t9Zj/ouM3wCE1EREREREREREREREREREREREREREREREREREREREREREREREREpNuWA1nXSBYR1kRERGQaN8jSTtbiXlnaE//bdG00iCruOozrMwHfH3Dd0Lx1kbX4l+2VOkjddK2n180ua1LU401XNXkRMEjpGgQsdpGuLWA2Hc8Cb7uI5DhFUfSztldXL+D2HhIBy22m633FItluK11PA65HRBEBPwMW2ojkHbBUcW4e2Jk0kicBPyqiKHo/4NkkkewAvTHXPAc+NY1kKeCmdMcnAVfp+DTgvHTuV8CrJkv4ME3wJ2AvIA+4SGNfAuYCdgN+p7GjgKwO8iHd3deA1dJ4GSnGXgYcpJX2sQ7yOmB+xEIYhRQ9H3o4S/PmFaW6aPCOOQAu/dwlIiIiIiIiIiIiIiIiUqcN/3A2zV8+51W6hReZDiTPvvUf5TnxP3BERERERERERERERERERERERERERERERERERERERERERERERERERMa3vwMAUq/rf5uqvocAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the recurrent cell\n",
    "\n",
    "![1HiddenRNNFeed.PNG](attachment:1HiddenRNNFeed.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Cell\n",
    "\n",
    "24 neurons in the hidden layer\n",
    "\n",
    "(In the image, 1 neuron, in the code, num_hidden neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_hidden = 24\n",
    "\n",
    "rnn_cell = tf.contrib.rnn.BasicRNNCell(num_units=num_hidden)"
   ]
  },
  {
   "attachments": {
    "1HiddenRNNUnrolled.PNG": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAAEZCAYAAAA+OA+2AAAACXBIWXMAAC4jAAAuIwF4pT92AAAAIGNIUk0AAHolAACAgwAA+f8AAIDpAAB1MAAA6mAAADqYAAAXb5JfxUYAAATwSURBVHja7N3Pi9RlHMDx9+hiGh2igjAIU7oUYUU/LtExLIiiKIOIKIgkkCKIIBI6mBEEXRTsFnWT/oeKIOhQlw4hKXSpS5CVdMms7eAEa7gZm85+v99er8s4zO4Mn8f3Pjwzjjuz/R1sEfYt713I47w+O1S1vICHmi1ipqnMs6g5lha1WMECbLAECBoEDYIGQSNoEDQIGgQNgkbQIGgQNAgaBI2gQdAgaBA0CBpBg6BB0CBoEDSCBkGDoEHQIGgEDYIGQYOgQdAIGgQNggZBI2gQNAzR0kIfbXaRP1B2eTnzDHWexXwE95h26J3VlgltJlOaZzCzjCnozdWeCQU9pXkGM8uYgj5evVZtnUgEU5pnMLOMKegT1Y/Vu9XGCUQwpXkGM8vYXuX4sNpVvT2RXXpK8wxilrEF/dH88vnqrWo28gimNM8gZllap+E/X+P3Xbrizy9VO6qnq5Pr/Jc5pXlGPct6BX3bBbqfh6s/qkfXOegpzTPqWdYr6A/W+H2bqgdXXH+/YbxcNKV5Rj3LegW9e43f98SKRXuzemUg58cpzTPqWcb2pPDu+eU7A4rZPAOaZYxBf1a90DRMaZ5BzLI0ogXbXF1X3VydmkAAU5pnMLOMaYfeVh2ujk1kd57SPIOZZUxBz6oDTceU5hnMLGM6chxtWo6axZNCGNAOvej/gWGe4cwzO2SHBkEjaBA0CBoEDYJG0CBoEDQIGgSNoEHQIGgQNAgaQYOgQdAgaBA0ggZBg6BB0CBoBA2CBkGDoEHQCBoEDYIGQSNoS4CgYaCWJjrXzDz/zzlm+zu4kEn2Le+1fXDxf2KWp/bhkThDg6BB0CBoEDSCBkGDoEHQIGgEDeN19rvtZhfwzVDeI4IdGhYf9L2WjaE6++2j5z9ybKi+qG515GAKO/Tt1S3VjZaOKQS9a355n6VjCkH/dX5+wNIx9jP01dV31cbq9+qa6ntnaMa6Qz80j7n55SOWjzEHvftv1x+3fIz1yLG9On6OH4AbqqOOHIxth35qla991hIyth36kuqbaus5bvulurb6yQ7NWHboJ1eJueqyao9lZCw79Kb5GXn7P9zHiWpH9bMdmqHv0HvOE3PVFdXLlpKh79Bbq6+qy+fXP57Hva36pNpS3TG/7ddqZ/W1HZqh7tAH5zGfrt6o7qlOzm/7trqrOlCdmj9xPNz0fo0tEwn6uer+6kh1Z/XqPOyVfqv2VTdV782/7kVLynpa7Reef1pd1ZmX5c7nWGdep36mut6SMsSgv1zDfZ1utX81hAGcoUHQIGgQNAgaQYOgQdAgaBA0ggZBg6BB0CBoBA2CBkGDoBE0CBoEDYIGQSNoEDQIGgQNgkbQIGgQNAgaBI2gQdCw3v7Nh9evjQ/exA4N/82SXRU7NAgaBA2CRtAgaBiapdmRHxbyQMuPXWm1ufhBV4t48XlmqXHkAEEjaBA0CBoEDYJG0CBoEDQIGgSNoEHQIGgQNAgaQYOgQdAgaBA0ggZBg6BB0CBoBA2CBkGDoEHQCBoEDYIGQSNoEDQIGgQNgkbQIGgQNAgaBI2gQdAgaBA0CBpBg6BB0CBoEDSCBkGDoEHQIGgEDYIGQYOgQdAIGgQNggZBg6ARNAgaBA2CRtAgaBA0CBoEjaBB0CBoEDQIGkGDoEHQIGgQNIIGQYOgQdAgaAQNggZBg6DhLH8OAABZvOFQXzg0AAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Net\n",
    "\n",
    "*dynamic_rnn():* Creates a recurrent neural network specified by RNNCell `cell`.\n",
    "\n",
    "*returns:*A pair (outputs, state)\n",
    "\n",
    "### Unfold the cell\n",
    "\n",
    "![1HiddenRNNUnrolled.PNG](attachment:1HiddenRNNUnrolled.PNG)\n",
    "\n",
    "(In the image, 1 neuron, in the code, num_hidden neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*dynamic_rnn:* The [inputs] is a single Tensor where the maximum time is the second dimension [batch_size,max_time,...]\n",
    "\n",
    "In this case, **max_time** is equal to **Sequence length**\n",
    "\n",
    "Do you remember our Placeholders? Yup. Now it seems that they fit perfectly here, that's why they were a little bit different, to match here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output,state = tf.nn.dynamic_rnn(cell=rnn_cell,inputs=data,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/transpose:0\", shape=(?, 10, 24), dtype=float32) < -- shape=(AnyBatchSize, SequenceLenght, NumberHiddenNeurons)\n",
      "Tensor(\"rnn/while/Exit_2:0\", shape=(?, 24), dtype=float32) < -- shape=(AnyBatchSize, NumberHiddenNeurons)\n"
     ]
    }
   ],
   "source": [
    "print(output,'< -- shape=(AnyBatchSize, SequenceLenght, NumberHiddenNeurons)')\n",
    "print(state,'< -- shape=(AnyBatchSize, NumberHiddenNeurons)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transpose**\n",
    "\n",
    "Let's look at the operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 5) \n",
      "\n",
      "(3, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "test = np.array(np.random.choice(size=15,a=10)).reshape(1,3,5)\n",
    "print(test.shape,'\\n')\n",
    "\n",
    "trans = test.transpose([1,0,2])\n",
    "print(trans.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the output transposed **Â¿Why?** \n",
    "\n",
    "Because we only want the output of the last step in the sequence\n",
    "\n",
    "Initial shape: [batch_size,sequence lenght,hidden_nodes]\n",
    "\n",
    "Final shape = [sequence lenght,batch_size,hidden_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"transpose_1:0\", shape=(10, ?, 24), dtype=float32) < -- shape=(SequenceLenght,AnyBatchSize, NumberHiddenNeurons)\n"
     ]
    }
   ],
   "source": [
    "output = tf.transpose(output,[1,0,2])\n",
    "print(output,'< -- shape=(SequenceLenght,AnyBatchSize, NumberHiddenNeurons)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an **output** for each **sequence step** but we only want the  **last one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LastIndex: 9\n"
     ]
    }
   ],
   "source": [
    "lastIndex = output.get_shape()[0]-1\n",
    "print('LastIndex: %d' % lastIndex)\n",
    "\n",
    "last = tf.gather(params=output,indices=lastIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the last input has dimension equal to the number of neurons in the recurrent hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Gather:0' shape=(?, 24) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last"
   ]
  },
  {
   "attachments": {
    "1HiddenRNNUnrolledOutput.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After the Unrolled RNN**\n",
    "\n",
    "Now we have the RNN rolled and we have the last output\n",
    "\n",
    "Then, we have to apply the final transformation to the output and map it to the output.\n",
    "\n",
    "![1HiddenRNNUnrolledOutput.PNG](attachment:1HiddenRNNUnrolledOutput.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the **out** weight and bias, for the last step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([num_hidden,output_size]))\n",
    "bias = tf.Variable(tf.constant(0.1,shape=[output_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the prediction, the operation of the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = tf.matmul(last,weight) + bias\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross entropy, optimizer, minimize..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.square(target - prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "minimize = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution of the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Cross-Entropy: 1686.26\n",
      "\n",
      "Puntual prediction on training set:\n",
      "For observation: [3 3 1 1 1 0 0 5 9 7] - Real: 30 - Prediction: 7 - Error: 23 \n",
      "\n",
      "Epoch: 1 - Cross-Entropy: 1211.07\n",
      "Epoch: 2 - Cross-Entropy: 1018.84\n",
      "Epoch: 3 - Cross-Entropy: 892.49\n",
      "Epoch: 4 - Cross-Entropy: 813.98\n",
      "Epoch: 5 - Cross-Entropy: 746.82\n",
      "Epoch: 6 - Cross-Entropy: 686.28\n",
      "Epoch: 7 - Cross-Entropy: 630.92\n",
      "Epoch: 8 - Cross-Entropy: 580.00\n",
      "Epoch: 9 - Cross-Entropy: 533.09\n",
      "Epoch: 10 - Cross-Entropy: 489.85\n",
      "Epoch: 11 - Cross-Entropy: 450.02\n",
      "Epoch: 12 - Cross-Entropy: 413.36\n",
      "Epoch: 13 - Cross-Entropy: 379.67\n",
      "Epoch: 14 - Cross-Entropy: 348.77\n",
      "Epoch: 15 - Cross-Entropy: 320.47\n",
      "Epoch: 16 - Cross-Entropy: 294.63\n",
      "Epoch: 17 - Cross-Entropy: 271.07\n",
      "Epoch: 18 - Cross-Entropy: 249.66\n",
      "Epoch: 19 - Cross-Entropy: 230.25\n",
      "Epoch: 20 - Cross-Entropy: 212.70\n",
      "Epoch: 21 - Cross-Entropy: 196.89\n",
      "Epoch: 22 - Cross-Entropy: 182.68\n",
      "Epoch: 23 - Cross-Entropy: 169.96\n",
      "Epoch: 24 - Cross-Entropy: 158.60\n",
      "Epoch: 25 - Cross-Entropy: 148.51\n",
      "\n",
      "Puntual prediction on training set:\n",
      "For observation: [9 1 7 3 9 0 3 7 9 7] - Real: 55 - Prediction: 37 - Error: 18 \n",
      "\n",
      "Epoch: 26 - Cross-Entropy: 139.57\n",
      "Epoch: 27 - Cross-Entropy: 131.68\n",
      "Epoch: 28 - Cross-Entropy: 124.75\n",
      "Epoch: 29 - Cross-Entropy: 118.69\n",
      "Epoch: 30 - Cross-Entropy: 113.41\n",
      "Epoch: 31 - Cross-Entropy: 108.83\n",
      "Epoch: 32 - Cross-Entropy: 104.88\n",
      "Epoch: 33 - Cross-Entropy: 101.49\n",
      "Epoch: 34 - Cross-Entropy: 98.59\n",
      "Epoch: 35 - Cross-Entropy: 96.12\n",
      "Epoch: 36 - Cross-Entropy: 94.04\n",
      "Epoch: 37 - Cross-Entropy: 92.29\n",
      "Epoch: 38 - Cross-Entropy: 90.82\n",
      "Epoch: 39 - Cross-Entropy: 89.60\n",
      "Epoch: 40 - Cross-Entropy: 88.60\n",
      "Epoch: 41 - Cross-Entropy: 87.77\n",
      "Epoch: 42 - Cross-Entropy: 87.09\n",
      "Epoch: 43 - Cross-Entropy: 86.54\n",
      "Epoch: 44 - Cross-Entropy: 86.10\n",
      "Epoch: 45 - Cross-Entropy: 85.74\n",
      "Epoch: 46 - Cross-Entropy: 85.45\n",
      "Epoch: 47 - Cross-Entropy: 85.22\n",
      "Epoch: 48 - Cross-Entropy: 85.04\n",
      "Epoch: 49 - Cross-Entropy: 84.90\n",
      "Epoch: 50 - Cross-Entropy: 84.78\n",
      "\n",
      "Puntual prediction on training set:\n",
      "For observation: [8 2 5 5 8 4 7 3 9 7] - Real: 58 - Prediction: 45 - Error: 13 \n",
      "\n",
      "Epoch: 51 - Cross-Entropy: 84.69\n",
      "Epoch: 52 - Cross-Entropy: 84.61\n",
      "Epoch: 53 - Cross-Entropy: 84.54\n",
      "Epoch: 54 - Cross-Entropy: 84.47\n",
      "Epoch: 55 - Cross-Entropy: 84.38\n",
      "Epoch: 56 - Cross-Entropy: 82.18\n",
      "Epoch: 57 - Cross-Entropy: 79.83\n",
      "Epoch: 58 - Cross-Entropy: 77.91\n",
      "Epoch: 59 - Cross-Entropy: 71.86\n",
      "Epoch: 60 - Cross-Entropy: 59.87\n",
      "Epoch: 61 - Cross-Entropy: 43.13\n",
      "Epoch: 62 - Cross-Entropy: 35.84\n",
      "Epoch: 63 - Cross-Entropy: 31.82\n",
      "Epoch: 64 - Cross-Entropy: 28.47\n",
      "Epoch: 65 - Cross-Entropy: 25.67\n",
      "Epoch: 66 - Cross-Entropy: 23.21\n",
      "Epoch: 67 - Cross-Entropy: 21.12\n",
      "Epoch: 68 - Cross-Entropy: 19.32\n",
      "Epoch: 69 - Cross-Entropy: 17.76\n",
      "Epoch: 70 - Cross-Entropy: 16.39\n",
      "Epoch: 71 - Cross-Entropy: 15.16\n",
      "Epoch: 72 - Cross-Entropy: 14.05\n",
      "Epoch: 73 - Cross-Entropy: 13.05\n",
      "Epoch: 74 - Cross-Entropy: 12.15\n",
      "Epoch: 75 - Cross-Entropy: 11.33\n",
      "\n",
      "Puntual prediction on training set:\n",
      "For observation: [7 0 7 3 7 1 3 5 7 5] - Real: 45 - Prediction: 46 - Error: -1 \n",
      "\n",
      "Epoch: 76 - Cross-Entropy: 10.58\n",
      "Epoch: 77 - Cross-Entropy: 9.90\n",
      "Epoch: 78 - Cross-Entropy: 9.27\n",
      "Epoch: 79 - Cross-Entropy: 8.69\n",
      "Epoch: 80 - Cross-Entropy: 8.16\n",
      "Epoch: 81 - Cross-Entropy: 7.68\n",
      "Epoch: 82 - Cross-Entropy: 7.22\n",
      "Epoch: 83 - Cross-Entropy: 6.81\n",
      "Epoch: 84 - Cross-Entropy: 6.42\n",
      "Epoch: 85 - Cross-Entropy: 6.06\n",
      "Epoch: 86 - Cross-Entropy: 5.72\n",
      "Epoch: 87 - Cross-Entropy: 5.41\n",
      "Epoch: 88 - Cross-Entropy: 5.11\n",
      "Epoch: 89 - Cross-Entropy: 4.84\n",
      "Epoch: 90 - Cross-Entropy: 4.59\n",
      "Epoch: 91 - Cross-Entropy: 4.35\n",
      "Epoch: 92 - Cross-Entropy: 4.13\n",
      "Epoch: 93 - Cross-Entropy: 3.92\n",
      "Epoch: 94 - Cross-Entropy: 3.72\n",
      "Epoch: 95 - Cross-Entropy: 3.53\n",
      "Epoch: 96 - Cross-Entropy: 3.35\n",
      "Epoch: 97 - Cross-Entropy: 3.18\n",
      "Epoch: 98 - Cross-Entropy: 3.02\n",
      "Epoch: 99 - Cross-Entropy: 2.87\n",
      "Epoch: 100 - Cross-Entropy: 2.74\n",
      "\n",
      "Puntual prediction on training set:\n",
      "For observation: [1 5 5 2 7 8 2 4 9 0] - Real: 43 - Prediction: 43 - Error: 0 \n",
      "\n",
      "Epoch: 101 - Cross-Entropy: 2.61\n",
      "Epoch: 102 - Cross-Entropy: 2.49\n",
      "Epoch: 103 - Cross-Entropy: 2.38\n",
      "Epoch: 104 - Cross-Entropy: 2.28\n",
      "Epoch: 105 - Cross-Entropy: 2.18\n",
      "Epoch: 106 - Cross-Entropy: 2.08\n",
      "Epoch: 107 - Cross-Entropy: 1.98\n",
      "Epoch: 108 - Cross-Entropy: 1.88\n",
      "Epoch: 109 - Cross-Entropy: 1.79\n",
      "Epoch: 110 - Cross-Entropy: 1.71\n",
      "Epoch: 111 - Cross-Entropy: 1.63\n",
      "Epoch: 112 - Cross-Entropy: 1.56\n",
      "Epoch: 113 - Cross-Entropy: 1.49\n",
      "Epoch: 114 - Cross-Entropy: 1.42\n",
      "Epoch: 115 - Cross-Entropy: 1.36\n",
      "Epoch: 116 - Cross-Entropy: 1.31\n",
      "Epoch: 117 - Cross-Entropy: 1.25\n",
      "Epoch: 118 - Cross-Entropy: 1.20\n",
      "Epoch: 119 - Cross-Entropy: 1.15\n",
      "Epoch: 120 - Cross-Entropy: 1.11\n",
      "Epoch: 121 - Cross-Entropy: 1.06\n",
      "Epoch: 122 - Cross-Entropy: 1.02\n",
      "Epoch: 123 - Cross-Entropy: 0.99\n",
      "Epoch: 124 - Cross-Entropy: 0.95\n",
      "Epoch: 125 - Cross-Entropy: 0.91\n",
      "\n",
      "Puntual prediction on training set:\n",
      "For observation: [7 0 7 3 7 1 3 5 7 5] - Real: 45 - Prediction: 45 - Error: -0 \n",
      "\n",
      "Epoch: 126 - Cross-Entropy: 0.88\n",
      "Epoch: 127 - Cross-Entropy: 0.84\n",
      "Epoch: 128 - Cross-Entropy: 0.81\n",
      "Epoch: 129 - Cross-Entropy: 0.78\n",
      "Epoch: 130 - Cross-Entropy: 0.75\n",
      "Epoch: 131 - Cross-Entropy: 0.72\n",
      "Epoch: 132 - Cross-Entropy: 0.69\n",
      "Epoch: 133 - Cross-Entropy: 0.66\n",
      "Epoch: 134 - Cross-Entropy: 0.63\n",
      "Epoch: 135 - Cross-Entropy: 0.60\n",
      "Epoch: 136 - Cross-Entropy: 0.57\n",
      "Epoch: 137 - Cross-Entropy: 0.55\n",
      "Epoch: 138 - Cross-Entropy: 0.52\n",
      "Epoch: 139 - Cross-Entropy: 0.50\n",
      "Epoch: 140 - Cross-Entropy: 0.48\n",
      "Epoch: 141 - Cross-Entropy: 0.47\n",
      "Epoch: 142 - Cross-Entropy: 0.45\n",
      "Epoch: 143 - Cross-Entropy: 0.44\n",
      "Epoch: 144 - Cross-Entropy: 0.42\n",
      "Epoch: 145 - Cross-Entropy: 0.40\n",
      "Epoch: 146 - Cross-Entropy: 0.38\n",
      "Epoch: 147 - Cross-Entropy: 0.37\n",
      "Epoch: 148 - Cross-Entropy: 0.35\n",
      "Epoch: 149 - Cross-Entropy: 0.34\n",
      "Epoch: 150 - Cross-Entropy: 0.33\n",
      "\n",
      "Puntual prediction on training set:\n",
      "For observation: [6 6 8 5 6 2 0 2 2 6] - Real: 43 - Prediction: 43 - Error: 0 \n",
      "\n",
      "Epoch: 151 - Cross-Entropy: 0.32\n",
      "Epoch: 152 - Cross-Entropy: 0.31\n",
      "Epoch: 153 - Cross-Entropy: 0.30\n",
      "Epoch: 154 - Cross-Entropy: 0.29\n",
      "Epoch: 155 - Cross-Entropy: 0.28\n",
      "Epoch: 156 - Cross-Entropy: 0.27\n",
      "Epoch: 157 - Cross-Entropy: 0.26\n",
      "Epoch: 158 - Cross-Entropy: 0.25\n",
      "Epoch: 159 - Cross-Entropy: 0.24\n",
      "Epoch: 160 - Cross-Entropy: 0.24\n",
      "Epoch: 161 - Cross-Entropy: 0.23\n",
      "Epoch: 162 - Cross-Entropy: 0.22\n",
      "Epoch: 163 - Cross-Entropy: 0.21\n",
      "Epoch: 164 - Cross-Entropy: 0.21\n",
      "Epoch: 165 - Cross-Entropy: 0.20\n",
      "Epoch: 166 - Cross-Entropy: 0.19\n",
      "Epoch: 167 - Cross-Entropy: 0.19\n",
      "Epoch: 168 - Cross-Entropy: 0.18\n",
      "Epoch: 169 - Cross-Entropy: 0.17\n",
      "Epoch: 170 - Cross-Entropy: 0.17\n",
      "Epoch: 171 - Cross-Entropy: 0.16\n",
      "Epoch: 172 - Cross-Entropy: 0.16\n",
      "Epoch: 173 - Cross-Entropy: 0.15\n",
      "Epoch: 174 - Cross-Entropy: 0.15\n",
      "Epoch: 175 - Cross-Entropy: 0.14\n",
      "\n",
      "Puntual prediction on training set:\n",
      "For observation: [2 7 7 2 5 9 8 7 6 1] - Real: 54 - Prediction: 54 - Error: -0 \n",
      "\n",
      "Epoch: 176 - Cross-Entropy: 0.14\n",
      "Epoch: 177 - Cross-Entropy: 0.14\n",
      "Epoch: 178 - Cross-Entropy: 0.13\n",
      "Epoch: 179 - Cross-Entropy: 0.13\n",
      "Epoch: 180 - Cross-Entropy: 0.12\n",
      "Epoch: 181 - Cross-Entropy: 0.12\n",
      "Epoch: 182 - Cross-Entropy: 0.12\n",
      "Epoch: 183 - Cross-Entropy: 0.11\n",
      "Epoch: 184 - Cross-Entropy: 0.11\n",
      "Epoch: 185 - Cross-Entropy: 0.11\n",
      "Epoch: 186 - Cross-Entropy: 0.11\n",
      "Epoch: 187 - Cross-Entropy: 0.10\n",
      "Epoch: 188 - Cross-Entropy: 0.10\n",
      "Epoch: 189 - Cross-Entropy: 0.10\n",
      "Epoch: 190 - Cross-Entropy: 0.10\n",
      "Epoch: 191 - Cross-Entropy: 0.09\n",
      "Epoch: 192 - Cross-Entropy: 0.09\n",
      "Epoch: 193 - Cross-Entropy: 0.09\n",
      "Epoch: 194 - Cross-Entropy: 0.09\n",
      "Epoch: 195 - Cross-Entropy: 0.09\n",
      "Epoch: 196 - Cross-Entropy: 0.08\n",
      "Epoch: 197 - Cross-Entropy: 0.08\n",
      "Epoch: 198 - Cross-Entropy: 0.08\n",
      "Epoch: 199 - Cross-Entropy: 0.08\n",
      "\n",
      "Test results:\n",
      "For mini batch of test observations:\n",
      "[8 8 2 2 2 9 6 1 1 6] - Real: 45 - Prediction: 45 - Error: -0\n",
      "[4 2 7 8 2 7 7 1 9 4] - Real: 51 - Prediction: 51 - Error: 0\n",
      "[7 7 7 0 5 2 5 3 4 5] - Real: 45 - Prediction: 45 - Error: -0\n",
      "[6 9 5 8 7 6 4 4 7 0] - Real: 56 - Prediction: 56 - Error: 0\n",
      "[5 7 3 2 6 1 9 5 1 3] - Real: 42 - Prediction: 42 - Error: 0\n",
      "Cross-entropy 0.08\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    batch_size = 100\n",
    "    no_of_batches = int(len(train_input)/batch_size)\n",
    "\n",
    "    epoch = 200\n",
    "    info_epoch = 25\n",
    "\n",
    "    for i in range(epoch):\n",
    "        ce = sess.run(cross_entropy,{data : test_input, target : test_output})\n",
    "        print('Epoch: %d - Cross-Entropy: %.2f' %(i,ce))\n",
    "        \n",
    "        ptr = 0\n",
    "        if (i % info_epoch == 0):\n",
    "                print('\\nPuntual prediction on training set:')\n",
    "                \n",
    "        for j in range(no_of_batches):\n",
    "            \n",
    "            inp = train_input[ptr:ptr+batch_size]\n",
    "            out = train_output[ptr:ptr+batch_size]\n",
    "            \n",
    "            ptr += batch_size\n",
    "            sess.run(minimize,{data:inp,target:out})\n",
    "\n",
    "            \n",
    "            if (i % info_epoch == 0 and j == 0):\n",
    "                random_sample = np.random.randint(0,batch_size)\n",
    "                pred = sess.run(prediction,{data:inp,target:out})\n",
    "                print('For observation: %s - Real: %.0f - Prediction: %.0f - Error: %.0f \\n' \n",
    "                      %(inp[random_sample].reshape(-1),\n",
    "                        np.sum(inp[random_sample].reshape(-1)),\n",
    "                        pred[random_sample],\n",
    "                        np.sum(inp[random_sample].reshape(-1)) - pred[random_sample]\n",
    "                       )\n",
    "                     )\n",
    "                \n",
    "            \n",
    "                  \n",
    "    print('\\nTest results:')\n",
    "    ce = sess.run(cross_entropy,{data : test_input, target : test_output})\n",
    "    pred_test = sess.run(prediction,{data:test_input,target:test_output})\n",
    "    print('For mini batch of test observations:')\n",
    "    for k in range(5):\n",
    "        print('%s - Real: %.0f - Prediction: %.0f - Error: %.0f' \n",
    "            %(test_input[k].reshape(-1),\n",
    "              np.sum(test_input[k].reshape(-1)),\n",
    "              pred_test[k],\n",
    "              np.sum(test_input[k].reshape(-1)) - pred_test[k]\n",
    "             )\n",
    "            )\n",
    "          \n",
    "                      \n",
    "    \n",
    "    print('Cross-entropy %.2f' % ce)\n",
    "\n",
    "    sess.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
